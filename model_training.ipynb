{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Sklearn ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, get_scorer_names\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle as pkl\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize k-fold value\n",
    "k=5\n",
    "# Initialize variable for first test/train split\n",
    "#test_percent = 1/(k+1)\n",
    "test_percent = 0.3\n",
    "#print(test_percent)\n",
    "\n",
    "# Mahalanobis threshold\n",
    "m_thresh = 0.05\n",
    "\n",
    "# Use same random seed to ensure reproducible results across runs\n",
    "#rand_seed = random.randint(0, 10000)\n",
    "rand_seed = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>class</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>...</th>\n",
       "      <th>f1014</th>\n",
       "      <th>f1015</th>\n",
       "      <th>f1016</th>\n",
       "      <th>f1017</th>\n",
       "      <th>f1018</th>\n",
       "      <th>f1019</th>\n",
       "      <th>f1020</th>\n",
       "      <th>f1021</th>\n",
       "      <th>f1022</th>\n",
       "      <th>f1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ZYURRE527</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.113097</td>\n",
       "      <td>-0.284965</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680631</td>\n",
       "      <td>-1.153061</td>\n",
       "      <td>0.111816</td>\n",
       "      <td>0.162622</td>\n",
       "      <td>-1.085265</td>\n",
       "      <td>-0.657002</td>\n",
       "      <td>-1.406191</td>\n",
       "      <td>2.240085</td>\n",
       "      <td>0.118616</td>\n",
       "      <td>-0.728013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ZWNWBP435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.045820</td>\n",
       "      <td>-0.216762</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.241972</td>\n",
       "      <td>-0.115316</td>\n",
       "      <td>-0.411191</td>\n",
       "      <td>0.431461</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>1.243681</td>\n",
       "      <td>-0.151721</td>\n",
       "      <td>0.458508</td>\n",
       "      <td>1.931918</td>\n",
       "      <td>-0.241081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ZVHEZA963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>-0.292385</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659314</td>\n",
       "      <td>-0.792833</td>\n",
       "      <td>-0.471358</td>\n",
       "      <td>0.514799</td>\n",
       "      <td>-0.846220</td>\n",
       "      <td>0.479314</td>\n",
       "      <td>-0.730218</td>\n",
       "      <td>1.352716</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.163302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ZSFNU1100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>-0.109248</td>\n",
       "      <td>-0.183284</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047666</td>\n",
       "      <td>-0.201043</td>\n",
       "      <td>-0.565545</td>\n",
       "      <td>0.999009</td>\n",
       "      <td>-0.332314</td>\n",
       "      <td>-0.066972</td>\n",
       "      <td>-1.263785</td>\n",
       "      <td>3.876905</td>\n",
       "      <td>-0.397950</td>\n",
       "      <td>-0.693763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ZRXUB1049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>-0.068301</td>\n",
       "      <td>-0.283487</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221178</td>\n",
       "      <td>-0.253239</td>\n",
       "      <td>-0.046740</td>\n",
       "      <td>0.242367</td>\n",
       "      <td>-0.379724</td>\n",
       "      <td>-0.893249</td>\n",
       "      <td>-0.957397</td>\n",
       "      <td>1.118245</td>\n",
       "      <td>0.181925</td>\n",
       "      <td>-0.024197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>422</td>\n",
       "      <td>AGHXWX765</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>-0.093583</td>\n",
       "      <td>0.133018</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260746</td>\n",
       "      <td>-0.741712</td>\n",
       "      <td>-0.887129</td>\n",
       "      <td>0.190525</td>\n",
       "      <td>0.216271</td>\n",
       "      <td>0.490549</td>\n",
       "      <td>-1.047399</td>\n",
       "      <td>1.875185</td>\n",
       "      <td>0.345561</td>\n",
       "      <td>-0.874318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>423</td>\n",
       "      <td>AFEOPC672</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.006178</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>-0.302020</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457373</td>\n",
       "      <td>-0.782917</td>\n",
       "      <td>-1.072765</td>\n",
       "      <td>1.180279</td>\n",
       "      <td>-0.111142</td>\n",
       "      <td>1.897755</td>\n",
       "      <td>-0.902370</td>\n",
       "      <td>0.552967</td>\n",
       "      <td>-0.314270</td>\n",
       "      <td>-1.198762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>AEEEIG737</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>-0.152744</td>\n",
       "      <td>-0.355706</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411773</td>\n",
       "      <td>0.232481</td>\n",
       "      <td>-0.527885</td>\n",
       "      <td>-0.305296</td>\n",
       "      <td>-0.189008</td>\n",
       "      <td>-0.592684</td>\n",
       "      <td>-1.144780</td>\n",
       "      <td>3.459698</td>\n",
       "      <td>-0.199579</td>\n",
       "      <td>-0.999165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>425</td>\n",
       "      <td>ADQRPH513</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>-0.092386</td>\n",
       "      <td>-0.434045</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147889</td>\n",
       "      <td>1.168724</td>\n",
       "      <td>-0.486698</td>\n",
       "      <td>1.134707</td>\n",
       "      <td>-0.029372</td>\n",
       "      <td>0.092189</td>\n",
       "      <td>-0.791921</td>\n",
       "      <td>1.786787</td>\n",
       "      <td>2.089036</td>\n",
       "      <td>-0.690614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>426</td>\n",
       "      <td>ABNTSS552</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.006601</td>\n",
       "      <td>-0.001318</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>-0.047733</td>\n",
       "      <td>-0.071875</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064665</td>\n",
       "      <td>-0.444786</td>\n",
       "      <td>-0.879349</td>\n",
       "      <td>1.048909</td>\n",
       "      <td>0.213126</td>\n",
       "      <td>1.170847</td>\n",
       "      <td>-1.172747</td>\n",
       "      <td>1.686595</td>\n",
       "      <td>0.482523</td>\n",
       "      <td>-0.440434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        uid  class        f0        f1        f2        f3  \\\n",
       "0             0  ZYURRE527      4  0.000462  0.005583 -0.001031  0.002307   \n",
       "1             1  ZWNWBP435      0  0.000220  0.006780 -0.000547  0.002183   \n",
       "2             2  ZVHEZA963      4  0.000405  0.007183 -0.000137  0.002612   \n",
       "3             3  ZSFNU1100      4  0.000388  0.003802  0.002121  0.001513   \n",
       "4             4  ZRXUB1049      0  0.000425  0.006544  0.001630  0.001549   \n",
       "..          ...        ...    ...       ...       ...       ...       ...   \n",
       "422         422  AGHXWX765      0  0.000305  0.003671 -0.004093  0.003010   \n",
       "423         423  AFEOPC672      3  0.000441  0.006178 -0.000811  0.003572   \n",
       "424         424  AEEEIG737      3  0.000464  0.006611  0.000842  0.001412   \n",
       "425         425  ADQRPH513      3  0.000233  0.003029  0.001606  0.001224   \n",
       "426         426  ABNTSS552      4  0.000233  0.006601 -0.001318  0.001098   \n",
       "\n",
       "           f4        f5        f6  ...     f1014     f1015     f1016  \\\n",
       "0   -0.113097 -0.284965  0.001069  ...  0.680631 -1.153061  0.111816   \n",
       "1   -0.045820 -0.216762  0.000987  ... -1.241972 -0.115316 -0.411191   \n",
       "2   -0.083430 -0.292385  0.001094  ...  0.659314 -0.792833 -0.471358   \n",
       "3   -0.109248 -0.183284  0.000813  ... -0.047666 -0.201043 -0.565545   \n",
       "4   -0.068301 -0.283487  0.001004  ... -1.221178 -0.253239 -0.046740   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "422 -0.093583  0.133018  0.000627  ... -0.260746 -0.741712 -0.887129   \n",
       "423 -0.108863 -0.302020  0.000761  ...  0.457373 -0.782917 -1.072765   \n",
       "424 -0.152744 -0.355706  0.000906  ...  0.411773  0.232481 -0.527885   \n",
       "425 -0.092386 -0.434045  0.000668  ... -0.147889  1.168724 -0.486698   \n",
       "426 -0.047733 -0.071875  0.000654  ... -0.064665 -0.444786 -0.879349   \n",
       "\n",
       "        f1017     f1018     f1019     f1020     f1021     f1022     f1023  \n",
       "0    0.162622 -1.085265 -0.657002 -1.406191  2.240085  0.118616 -0.728013  \n",
       "1    0.431461  0.442649  1.243681 -0.151721  0.458508  1.931918 -0.241081  \n",
       "2    0.514799 -0.846220  0.479314 -0.730218  1.352716  0.040223 -0.163302  \n",
       "3    0.999009 -0.332314 -0.066972 -1.263785  3.876905 -0.397950 -0.693763  \n",
       "4    0.242367 -0.379724 -0.893249 -0.957397  1.118245  0.181925 -0.024197  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "422  0.190525  0.216271  0.490549 -1.047399  1.875185  0.345561 -0.874318  \n",
       "423  1.180279 -0.111142  1.897755 -0.902370  0.552967 -0.314270 -1.198762  \n",
       "424 -0.305296 -0.189008 -0.592684 -1.144780  3.459698 -0.199579 -0.999165  \n",
       "425  1.134707 -0.029372  0.092189 -0.791921  1.786787  2.089036 -0.690614  \n",
       "426  1.048909  0.213126  1.170847 -1.172747  1.686595  0.482523 -0.440434  \n",
       "\n",
       "[427 rows x 1027 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in dataset\n",
    "df = pd.read_csv(\"data/full_dataset.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of feature names\n",
    "feature_names = [name for name in df.columns if name.startswith(\"f\")]\n",
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    111\n",
       "4     76\n",
       "3     54\n",
       "1     38\n",
       "2     19\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set by class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    48\n",
       "4    33\n",
       "3    24\n",
       "1    16\n",
       "2     8\n",
       "Name: class, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = df[feature_names]\n",
    "y_all = df[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=test_percent, random_state=rand_seed, stratify=y_all\n",
    ")\n",
    "\n",
    "# Reset train index\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(\"Training set by class:\")\n",
    "display(y_train.value_counts())\n",
    "print(\"Test set by class:\")\n",
    "display(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Data\n",
    "\n",
    "Use StandardScaler from sklearn. Standardize both X_train and X_test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup scaler\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "# Fit and transform scaling to training data\n",
    "X_train = scaler_std.fit_transform(X_train)\n",
    "# Transform testing data using same fit\n",
    "X_test = scaler_std.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30424846, -1.12221261,  1.36300619, ..., -1.6839747 ,\n",
       "         0.79039146,  0.43540254],\n",
       "       [-0.41336697,  0.85306505, -0.11012979, ...,  1.05915341,\n",
       "         0.76792765, -0.68572629],\n",
       "       [-0.20625588,  0.38437699, -0.0850137 , ..., -0.53267344,\n",
       "         2.45674514,  0.59241311],\n",
       "       ...,\n",
       "       [-0.40652284,  0.39585126, -0.15626227, ...,  0.23483651,\n",
       "         0.78504705,  0.16681407],\n",
       "       [ 0.96244891,  0.86470823,  0.13107729, ..., -0.03687512,\n",
       "         0.20717153, -0.25255312],\n",
       "       [ 0.87266159, -0.3398418 , -1.16416682, ..., -0.88238011,\n",
       "        -0.10678945, -1.17119855]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store scaler_std so we can transform the blind test data in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'scaler_std' (StandardScaler)\n"
     ]
    }
   ],
   "source": [
    "%store scaler_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get single training DataFrame\n",
    "# norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "# norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "# # Standardize X_train values\n",
    "# X_train = norm_data(norm_df[feature_names])\n",
    "\n",
    "# # Get single testing DataFrame\n",
    "# norm_xtest_df = pd.DataFrame(X_test, columns=feature_names)\n",
    "# norm_test_df = pd.concat([y_test, norm_x_df], axis=1)\n",
    "# # Standardize X_test values (for later)\n",
    "# X_test = norm_data(norm_test_df[feature_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers\n",
    "\n",
    "Since we are in multi-dimensional space, we will use the mean and covariance matrices. This will be computed using Mahalanobis distance which is well-suited for multi-dimensional space: https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.mahalanobis.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that computes mean, cov matrix, and inv cov matrix\n",
    "def get_mean_cov(X_train):\n",
    "    # Merge dfs\n",
    "    norm_x_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "    norm_df = pd.concat([y_train, norm_x_df], axis=1)\n",
    "    # Compute mean and cov per class per feature\n",
    "    avg_list = []\n",
    "    cov_list = []\n",
    "    inv_cov_list = []\n",
    "    for i in range(5):\n",
    "        # Compute mean\n",
    "        avg = np.mean(norm_df[norm_df[\"class\"]==i][feature_names], axis=0)\n",
    "        avg_list.append(avg)\n",
    "        # Compute cov matrix\n",
    "        cov = np.cov(norm_df[norm_df[\"class\"]==i][feature_names], rowvar=False)\n",
    "        cov_list.append(cov)\n",
    "        # Compute inverse of cov matrix\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "        inv_cov_list.append(inv_cov)\n",
    "    return norm_df, avg_list, inv_cov_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test get_mean_cov function\n",
    "norm_df, avg_list, inv_cov_list = get_mean_cov(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    298.000000\n",
       "mean      32.655150\n",
       "std       16.689207\n",
       "min        2.359362\n",
       "25%       21.363562\n",
       "50%       30.543926\n",
       "75%       40.980192\n",
       "max      111.688343\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 3363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which features should be removed (identify outliers based on Mahalanobis dist)\n",
    "# Create function that computes Mahalanobis distance and adds it to norm_df\n",
    "def get_mahalanobis_dist(label, features):\n",
    "    u = avg_list[label]\n",
    "    v = features\n",
    "    vi = inv_cov_list[label]\n",
    "    delta = u - v\n",
    "    m = np.dot(np.dot(delta, vi), delta)\n",
    "    #dist = distance.mahalanobis(u, features, vi)\n",
    "    return np.sqrt(np.abs(m))\n",
    "\n",
    "# Call function for each feature\n",
    "norm_df[\"mahalanobis_dist\"] = norm_df.apply(lambda row: get_mahalanobis_dist(int(row[\"class\"]), row[feature_names]), axis=1)\n",
    "norm_df[\"mahalanobis_dist\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "def drop_outliers(norm_df, threshold):\n",
    "    # Remove threshold% of outliers by class\n",
    "    for i in range(5):\n",
    "        # Get threshold% of outliers for each class\n",
    "        threshold_num = norm_df[norm_df[\"class\"]==i][\"mahalanobis_dist\"].quantile(1-threshold)\n",
    "        # Drop threshold% of outliers for each class\n",
    "        norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)        \n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heath\\AppData\\Local\\Temp\\ipykernel_13048\\977542497.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  norm_df = norm_df.drop(norm_df[norm_df[\"class\"]==i][norm_df[\"mahalanobis_dist\"]>threshold_num].index)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    282.000000\n",
       "mean      30.914142\n",
       "std       14.687644\n",
       "min        2.359362\n",
       "25%       20.752967\n",
       "50%       29.158105\n",
       "75%       39.450062\n",
       "max       90.028271\n",
       "Name: mahalanobis_dist, dtype: float64"
      ]
     },
     "execution_count": 3365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test drop_outliers function\n",
    "norm_df = drop_outliers(norm_df, m_thresh)\n",
    "\n",
    "# Print updated descriptive stats\n",
    "norm_df[\"mahalanobis_dist\"].describe()\n",
    "#print(len(norm_df[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X_train and y_train\n",
    "X_train = norm_df[feature_names]\n",
    "y_train = norm_df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample Data\n",
    "\n",
    "Use ADASYN technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function that oversamples or undersamples data\n",
    "def resample(sampler, X_train, y_train, name):\n",
    "    X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "    # Observe number of classes after resample\n",
    "    #print(f\"Number of samples per class after {name}:\\n{y_train.value_counts()}\")\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test resample function\n",
    "# Setup ADASYN (oversampling)\n",
    "ada = ADASYN(random_state=rand_seed, sampling_strategy=\"minority\", n_neighbors=4)\n",
    "\n",
    "# Call resample function\n",
    "X_train, y_train = resample(ada, X_train, y_train, \"ADASYN Oversampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372, 1024)\n",
      "2    108\n",
      "0    105\n",
      "4     72\n",
      "3     51\n",
      "1     36\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# List from Azure ML Designer (Filter Based Feature Selection)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m azureml_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39moutputs/feature_selection/azureml_designer_features.csv\u001b[39m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# List from recursive feature elimination w/ and w/o cross-validation\u001b[39;00m\n\u001b[0;32m      4\u001b[0m rfe_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39moutputs/feature_selection/CommonFeatures_RFE_RFECV.csv\u001b[39m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# List from Azure ML Designer (Filter Based Feature Selection)\n",
    "azureml_features = pd.read_csv(\"outputs/feature_selection/azureml_designer_features.csv\", header=None)\n",
    "# List from recursive feature elimination w/ and w/o cross-validation\n",
    "rfe_features = pd.read_csv(\"outputs/feature_selection/CommonFeatures_RFE_RFECV.csv\", header=None)\n",
    "\n",
    "rfe_features = rfe_features[0].to_numpy()\n",
    "#display(rfe_features)\n",
    "azureml_features = azureml_features[0].to_numpy()\n",
    "# display(azureml_features)\n",
    "\n",
    "# Get out common features\n",
    "#intersect_features = np.intersect1d(azureml_features, rfe_features)\n",
    "common_features = np.union1d(azureml_features, rfe_features)\n",
    "extracted_feature_names = [f\"f{i}\" for i in common_features]\n",
    "extracted_feature_names_nof = [f\"{i}\" for i in common_features]\n",
    "#print(extracted_feature_names)\n",
    "#display(extracted_feature_names)\n",
    "print(np.count_nonzero(common_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store extracted_feature_names for use in inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'common_features' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store common_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'extracted_feature_names_nof' (list)\n"
     ]
    }
   ],
   "source": [
    "%store extracted_feature_names_nof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training dataset with only\n",
    "# the subset of features included\n",
    "X_train = X_train[extracted_feature_names]\n",
    "#print(X_train)\n",
    "\n",
    "# Get testing dataset wiuth only\n",
    "# the subset of features included\n",
    "X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "X_test = X_test[extracted_feature_names]\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters to try\n",
    "c_range = np.arange(5,4000)\n",
    "params = {\n",
    "    'C': c_range,\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Setup classifier\n",
    "svm = SVC(random_state=rand_seed)\n",
    "# Configure random search from sklearn\n",
    "svm_clf = RandomizedSearchCV(svm, params, scoring='f1_macro', cv=k, random_state=rand_seed)\n",
    "# Perform hyperparameter search\n",
    "search = svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_params = search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'gamma': 'auto', 'C': 382}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115958</td>\n",
       "      <td>0.012558</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>721</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 721}</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.609713</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.060192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108305</td>\n",
       "      <td>0.013580</td>\n",
       "      <td>0.032675</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>303</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 303}</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098982</td>\n",
       "      <td>0.013556</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>1596</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.609713</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.060192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.089676</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>931</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 931}</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083433</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>382</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 382}</td>\n",
       "      <td>0.505238</td>\n",
       "      <td>0.628862</td>\n",
       "      <td>0.591835</td>\n",
       "      <td>0.687128</td>\n",
       "      <td>0.647002</td>\n",
       "      <td>0.612013</td>\n",
       "      <td>0.061577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.117038</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>2022</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.104609</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.030355</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>2352</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.609713</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.060192</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.090814</td>\n",
       "      <td>0.013932</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>650</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 650}</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.018175</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>3159</td>\n",
       "      <td>{'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>0.588141</td>\n",
       "      <td>0.622194</td>\n",
       "      <td>0.603114</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.051201</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>linear</td>\n",
       "      <td>auto</td>\n",
       "      <td>1969</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'C': 1969}</td>\n",
       "      <td>0.505238</td>\n",
       "      <td>0.628862</td>\n",
       "      <td>0.591835</td>\n",
       "      <td>0.687128</td>\n",
       "      <td>0.647002</td>\n",
       "      <td>0.612013</td>\n",
       "      <td>0.061577</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_kernel  \\\n",
       "0       0.115958      0.012558         0.037728        0.006554          rbf   \n",
       "1       0.108305      0.013580         0.032675        0.005535          rbf   \n",
       "2       0.098982      0.013556         0.031242        0.004518          rbf   \n",
       "3       0.089676      0.005782         0.027209        0.001758          rbf   \n",
       "4       0.083433      0.010457         0.023674        0.005341       linear   \n",
       "5       0.117038      0.012285         0.047902        0.017229          rbf   \n",
       "6       0.104609      0.006462         0.030355        0.003081          rbf   \n",
       "7       0.090814      0.013932         0.028485        0.006852          rbf   \n",
       "8       0.063391      0.001832         0.018175        0.000435          rbf   \n",
       "9       0.051201      0.001426         0.013521        0.000411       linear   \n",
       "\n",
       "  param_gamma param_C                                            params  \\\n",
       "0        auto     721      {'kernel': 'rbf', 'gamma': 'auto', 'C': 721}   \n",
       "1       scale     303     {'kernel': 'rbf', 'gamma': 'scale', 'C': 303}   \n",
       "2        auto    1596     {'kernel': 'rbf', 'gamma': 'auto', 'C': 1596}   \n",
       "3       scale     931     {'kernel': 'rbf', 'gamma': 'scale', 'C': 931}   \n",
       "4        auto     382   {'kernel': 'linear', 'gamma': 'auto', 'C': 382}   \n",
       "5       scale    2022    {'kernel': 'rbf', 'gamma': 'scale', 'C': 2022}   \n",
       "6        auto    2352     {'kernel': 'rbf', 'gamma': 'auto', 'C': 2352}   \n",
       "7       scale     650     {'kernel': 'rbf', 'gamma': 'scale', 'C': 650}   \n",
       "8       scale    3159    {'kernel': 'rbf', 'gamma': 'scale', 'C': 3159}   \n",
       "9        auto    1969  {'kernel': 'linear', 'gamma': 'auto', 'C': 1969}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.516667           0.703787           0.609713           0.588141   \n",
       "1           0.503301           0.703787           0.598150           0.588141   \n",
       "2           0.516667           0.703787           0.609713           0.588141   \n",
       "3           0.503301           0.703787           0.598150           0.588141   \n",
       "4           0.505238           0.628862           0.591835           0.687128   \n",
       "5           0.503301           0.703787           0.598150           0.588141   \n",
       "6           0.516667           0.703787           0.609713           0.588141   \n",
       "7           0.503301           0.703787           0.598150           0.588141   \n",
       "8           0.503301           0.703787           0.598150           0.588141   \n",
       "9           0.505238           0.628862           0.591835           0.687128   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.622194         0.608100        0.060192                3  \n",
       "1           0.622194         0.603114        0.064359                6  \n",
       "2           0.622194         0.608100        0.060192                3  \n",
       "3           0.622194         0.603114        0.064359                6  \n",
       "4           0.647002         0.612013        0.061577                1  \n",
       "5           0.622194         0.603114        0.064359                6  \n",
       "6           0.622194         0.608100        0.060192                3  \n",
       "7           0.622194         0.603114        0.064359                6  \n",
       "8           0.622194         0.603114        0.064359                6  \n",
       "9           0.647002         0.612013        0.061577                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(best_params)\n",
    "#display(search.cv_results_)\n",
    "\n",
    "hyperparam_results_df = pd.DataFrame(search.cv_results_)\n",
    "display(hyperparam_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_classifier_with_k_folds(classifier, n_splits=5, random_state=rand_seed):\n",
    "    classifiers = []\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "        classifier.fit(X_train_fold, y_train_fold)\n",
    "        classifiers.append(classifier)\n",
    "\n",
    "        y_pred = classifier.predict(X_test_fold)\n",
    "\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "        precision_scores.append(\n",
    "            precision_score(y_test_fold, y_pred, average=\"macro\")\n",
    "        )\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred, average=\"macro\"))\n",
    "\n",
    "    return classifiers, {\n",
    "        \"accuracy\": pd.Series(accuracy_scores).describe().to_dict(),\n",
    "        \"f1\": pd.Series(f1_scores).describe().to_dict(),\n",
    "        \"precision\": pd.Series(precision_scores).describe().to_dict(),\n",
    "        \"recall\": pd.Series(recall_scores).describe().to_dict(),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255),\n",
       "  SVC(C=382, gamma='auto', kernel='linear', random_state=255)],\n",
       " {'accuracy': {'count': 5.0,\n",
       "   'mean': 0.6695135135135135,\n",
       "   'std': 0.04652983522544055,\n",
       "   'min': 0.6,\n",
       "   '25%': 0.6621621621621622,\n",
       "   '50%': 0.6756756756756757,\n",
       "   '75%': 0.68,\n",
       "   'max': 0.7297297297297297},\n",
       "  'f1': {'count': 5.0,\n",
       "   'mean': 0.5884773384230273,\n",
       "   'std': 0.05214115687365137,\n",
       "   'min': 0.5352499260573794,\n",
       "   '25%': 0.5409101168899318,\n",
       "   '50%': 0.586973026973027,\n",
       "   '75%': 0.6231313131313132,\n",
       "   'max': 0.6561223090634856},\n",
       "  'precision': {'count': 5.0,\n",
       "   'mean': 0.5982153209109731,\n",
       "   'std': 0.05446210532604825,\n",
       "   'min': 0.5436853002070393,\n",
       "   '25%': 0.550952380952381,\n",
       "   '50%': 0.5900621118012422,\n",
       "   '75%': 0.636656314699793,\n",
       "   'max': 0.6697204968944099},\n",
       "  'recall': {'count': 5.0,\n",
       "   'mean': 0.5889567099567099,\n",
       "   'std': 0.04735348124534765,\n",
       "   'min': 0.5409523809523809,\n",
       "   '25%': 0.5457142857142856,\n",
       "   '50%': 0.5878787878787877,\n",
       "   '75%': 0.6188095238095238,\n",
       "   'max': 0.6514285714285715}})"
      ]
     },
     "execution_count": 3377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "analyze_classifier_with_k_folds(svm_final_clf, n_splits=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5116\n",
      "F1 macro score: 0.4828\n",
      "Precision: 0.4939\n",
      "Recall: 0.4795\n"
     ]
    }
   ],
   "source": [
    "# Fit model using best hyperparameters found in previous search\n",
    "svm_final_clf = SVC(**best_params, random_state=rand_seed)\n",
    "svm_model_final = svm_final_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model_final.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 macro score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation for evaluation\n",
    "cv_scores = cross_val_score(svm_model_final, X_train, y_train, cv=7,\n",
    "    scoring=\"f1_macro\")\n",
    "#print(cv_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the f1 macro score and random seed to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to store results\n",
    "results_df = pd.DataFrame(columns=[\"F1Score\", \"RandomSeed\", \"cv1\", \"cv2\", \"cv3\", \"cv4\", \"cv5\"])\n",
    "\n",
    "results_df.loc[0] = [f1, rand_seed, cv_scores[0], cv_scores[1], cv_scores[2],\n",
    "    cv_scores[3], cv_scores[4]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "# Check if csv exists\n",
    "file_path = \"outputs/training_pipeline_results.csv\"\n",
    "if os.path.isfile(file_path):\n",
    "    # Append new results\n",
    "    results_df.to_csv(file_path, mode=\"a\", header=False)\n",
    "else:\n",
    "    # Create new csv and add results\n",
    "    results_df.to_csv(file_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model for use in inference notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'svm_model_final' (SVC)\n"
     ]
    }
   ],
   "source": [
    "%store svm_model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.joblib']"
      ]
     },
     "execution_count": 3384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model as pickle\n",
    "s = pkl.dumps(svm_model_final)\n",
    "dump(svm_model_final, \"svm_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Meta Learning!\n",
    "\n",
    "In addition to the svm classifier above (svm), we'll use the VotingClassifier() from sklearn which takes multiple estimators as input, and implements a voting procedure. We will use the following classifiers:\n",
    "\n",
    "- SVM (already created)\n",
    "- Naive Bayes\n",
    "- kNN, k=5\n",
    "- Decision Tree, max depth = 8\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all the classifiers!\n",
    "# Naive Bayes\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# kNN, k=5\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Decision tree, max depth=8\n",
    "dt_clf = DecisionTreeClassifier(random_state=rand_seed, max_depth=8)\n",
    "\n",
    "# Logistic regression\n",
    "lr_clf = LogisticRegression(random_state=rand_seed, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.4729\n",
      "Ensemble F1 macro score: 0.4408\n",
      "Ensemble precision: 0.5031\n",
      "Ensemble recall: 0.4557\n"
     ]
    }
   ],
   "source": [
    "# Put them to a vote!\n",
    "ensemble_clf = VotingClassifier(estimators=[\n",
    "    ('svm', svm), ('nb', nb_clf), ('knn', knn_clf),\n",
    "    ('dt', dt_clf), ('lr', lr_clf)], voting='hard'\n",
    ")\n",
    "\n",
    "# Fit and predict with voting classifier\n",
    "ensemble_clf = ensemble_clf.fit(X_train, y_train)\n",
    "ensemble_pred = ensemble_clf.predict(X_test)\n",
    "\n",
    "# Get metrics\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_precision = precision_score(y_test, ensemble_pred, average=\"macro\")\n",
    "ensemble_recall = recall_score(y_test, ensemble_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Ensemble accuracy: {ensemble_acc:.4f}\")\n",
    "print(f\"Ensemble F1 macro score: {ensemble_f1:.4f}\")\n",
    "print(f\"Ensemble precision: {ensemble_precision:.4f}\")\n",
    "print(f\"Ensemble recall: {ensemble_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x26886d40a30>"
      ]
     },
     "execution_count": 3387,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, ensemble_pred, normalize=\"true\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Learning with Weighted Average!\n",
    "\n",
    "Based on classifier performance\n",
    "\n",
    "https://machinelearningmastery.com/weighted-average-ensemble-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Average F1 macro: 45.36198557320555\n",
      "Voting Classifier with Weighted Average and 9-fold cv f1 macro avg: 0.5826\n",
      "Voting Classifier with Weighted Average and 9-fold cv f1 macro std: 0.0913\n"
     ]
    }
   ],
   "source": [
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('svm', SVC(random_state=rand_seed)))\n",
    "    models.append(('lr', LogisticRegression(random_state=rand_seed, max_iter=1000)))\n",
    "    models.append(('dt', DecisionTreeClassifier(random_state=rand_seed, max_depth=8)))\n",
    "    models.append(('nb', GaussianNB()))\n",
    "    models.append(('knn', KNeighborsClassifier(n_neighbors=5)))\n",
    "    return models\n",
    "\n",
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    # fit and evaluate models\n",
    "    scores = list()\n",
    "    for name, model in models:\n",
    "        # fit the classifiers\n",
    "        model.fit(X_train, y_train)\n",
    "        # eval model\n",
    "        ypred = model.predict(X_test)\n",
    "        f1_macro_score = f1_score(y_test, ypred, average=\"macro\")\n",
    "        # store performance\n",
    "        scores.append(f1_macro_score)\n",
    "    # report model performance\n",
    "    return scores\n",
    "\n",
    "# get the base models\n",
    "models = get_models()\n",
    "# fit and eval each model\n",
    "scores = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "precision\n",
    "\n",
    "# Create ensemble\n",
    "voting_ensemble = VotingClassifier(estimators=models, voting='hard', weights=scores)\n",
    "# Fit the ensemble to the training dataset\n",
    "voting_ensemble_clf = voting_ensemble.fit(X_train, y_train)\n",
    "voting_ensemble_pred = voting_ensemble_clf.predict(X_test)\n",
    "# Evaluate predictions\n",
    "score = f1_score(y_test, voting_ensemble_pred, average=\"macro\")\n",
    "print(f\"Weighted Average F1 macro: {score*100}\")\n",
    "\n",
    "# Use cross validation for evaluation\n",
    "cv_scores = cross_val_score(voting_ensemble_clf, X_train, y_train, cv=9,\n",
    "    scoring=\"f1_macro\")\n",
    "avg_cv_scores = np.average(cv_scores)\n",
    "std_cv_scores = np.std(cv_scores)\n",
    "print(f\"Voting Classifier with Weighted Average and 9-fold cv f1 macro avg: {avg_cv_scores:.4f}\")\n",
    "print(f\"Voting Classifier with Weighted Average and 9-fold cv f1 macro std: {std_cv_scores:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5697, k=5\n",
    "0.5931, k=6\n",
    "0.5619, k=7\n",
    "0.5604, k=8\n",
    "0.5788, k=9\n",
    "0.5752, k=10\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pattern-classification')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1895724e0ba1d87308f72752509c0d197b6cd14cd38e9b4860259e222d188bca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
